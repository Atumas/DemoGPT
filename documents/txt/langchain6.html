<h1>Building Custom Tools for LLM Agents</h1><p><a href="https://www.pinecone.io/learn/langchain-agents">Agents</a> are one of the most powerful and fascinating approaches to using <strong>L</strong>arge <strong>L</strong>anguage <strong>M</strong>odels (LLMs). The explosion of interest in LLMs has made agents incredibly prevalent in AI-powered use cases.</p><p>Using agents allows us to give LLMs access to tools. These tools present an infinite number of possibilities. With tools, LLMs can search the web, do math, run code, and more.</p><p>The LangChain library provides a substantial selection of prebuilt tools. However, in many real-world projects, we’ll often find that only so many requirements can be satisfied by existing tools. Meaning we must modify existing tools or build entirely new ones.</p><p>This chapter will explore how to build custom tools for agents in LangChain. We’ll start with a couple of simple tools to help us understand the typical <em>tool building pattern</em> before moving on to more complex tools using other ML models to give us even more abilities like describing images.</p><div style="left:0;width:100%;height:0;position:relative;padding-bottom:56.25%"><iframe style="border:1;top:0;left:0;width:100%;height:100%;position:absolute" src="./langchain6_files/q-HNphrWsDE.html" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><hr><h2 id="building-tools">Building Tools</h2><p>At their core, tools are objects that consume some input, typically in the format of a <em>string</em> (text), and output some helpful information as a string.</p><p>In reality, they are little more than a simple function that we’d find in any code. The only difference is that tools take input from an LLM and feed their output to an LLM.</p><p>With that in mind, tools are relatively simple. Fortunately, we can build tools for our agents in no time.</p><p><em>(Follow along with the <a href="https://github.com/pinecone-io/examples/blob/master/generation/langchain/handbook/07-langchain-tools.ipynb">code notebook here!</a>)</em></p><h3 id="simple-calculator-tool">Simple Calculator Tool</h3><p>We will start with a simple custom tool. The tool is a simple calculator that calculates a circle’s circumference based on the circle’s radius.</p><p><img loading="lazy" src="./langchain6_files/langchain-tools-3.png" alt="circumference calculation from radius" width="100%"></p><p>To create the tool, we do the following:</p><div class="highlight"><div class="code-toolbar"><pre class="language-python line-numbers" tabindex="0"><code class="language-python" data-lang="python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>tools <span class="token keyword">import</span> BaseTool
<span class="token keyword">from</span> math <span class="token keyword">import</span> pi
<span class="token keyword">from</span> typing <span class="token keyword">import</span> Union
  

<span class="token keyword">class</span> <span class="token class-name">CircumferenceTool</span><span class="token punctuation">(</span>BaseTool<span class="token punctuation">)</span><span class="token punctuation">:</span>
      name <span class="token operator">=</span> <span class="token string">"Circumference calculator"</span>
      description <span class="token operator">=</span> <span class="token string">"use this tool when you need to calculate a circumference using the radius of a circle"</span>

    <span class="token keyword">def</span> <span class="token function">_run</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> radius<span class="token punctuation">:</span> Union<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">float</span><span class="token punctuation">(</span>radius<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2.0</span><span class="token operator">*</span>pi

    <span class="token keyword">def</span> <span class="token function">_arun</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> radius<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> NotImplementedError<span class="token punctuation">(</span><span class="token string">"This tool does not support async"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><p>Here we initialized our custom <code>CircumferenceTool</code> class using the <code>BaseTool</code> object from LangChain. We can think of the <code>BaseTool</code> as the required template for a LangChain tool.</p><p>We have two attributes that LangChain requires to recognize an object as a valid tool. Those are the <code>name</code> and <code>description</code> parameters.</p><p>The <code>description</code> is a <em>natural language</em> description of the tool the LLM uses to decide whether it needs to use it. Tool descriptions should be very explicit on what they do, when to use them, and when <em>not</em> to use them.</p><p>In our <code>description</code>, we did not define when <em>not</em> to use the tool. That is because the LLM seemed capable of identifying when this tool is needed. Adding <em>“when not to use it”</em> to the description can help if a tool is overused.</p><p>Following this, we have two methods, <code>_run</code> and <code>_arun</code>. When a tool is used, the <code>_run</code> method is called by default. The <code>_arun</code> method is called when a tool is to be used <em>asynchronously</em>. We do not cover async tools in this chapter, so, for now, we initialize it with a <code>NotImplementedError</code>.</p><p>From here, we need to initialize the LLM and conversational memory for the <em>conversational</em> agent. For the LLM, we will use OpenAI’s <code>gpt-3.5-turbo</code> model. To use this, we need an <a href="https://platform.openai.com/">OpenAI API key</a>.</p><p>When ready, we initialize the LLM and memory like so:</p><div class="highlight"><div class="code-toolbar"><pre class="language-python line-numbers" tabindex="0"><code class="language-python" data-lang="python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>conversation<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationBufferWindowMemory


<span class="token comment"># initialize LLM (we use ChatOpenAI because we'll later define a `chat` agent)</span>
llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
        openai_api_key<span class="token operator">=</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">,</span>
        temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
        model_name<span class="token operator">=</span><span class="token string">'gpt-3.5-turbo'</span>
<span class="token punctuation">)</span>

<span class="token comment"># initialize conversational memory</span>
conversational_memory <span class="token operator">=</span> ConversationBufferWindowMemory<span class="token punctuation">(</span>
        memory_key<span class="token operator">=</span><span class="token string">'chat_history'</span><span class="token punctuation">,</span>
        k<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
        return_messages<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><p>Here we initialize the LLM with a <code>temperature</code> of <code>0</code>. A low <code>temperature</code> is useful when using tools as it decreases the amount of “randomness” or “creativity” in the generated text of the LLMs, which is ideal for encouraging it to follow strict instructions — as required for tool usage.</p><p>In the <code>conversation_memory</code> object, we set <code>k=5</code> to “remember” the previous <em>five</em> human-AI interactions.</p><p>Now we initialize the agent itself. It requires the <code>llm</code> and <code>conversational_memory</code> to be already initialized. It also requires a list of <code>tools</code> to be used. We have one tool, but we still place it into a list.</p><div class="highlight"><div class="code-toolbar"><pre class="language-python line-numbers" tabindex="0"><code class="language-python" data-lang="python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>agents <span class="token keyword">import</span> initialize_agent

tools <span class="token operator">=</span> <span class="token punctuation">[</span>CircumferenceTool<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token comment"># initialize agent with tools</span>
agent <span class="token operator">=</span> initialize_agent<span class="token punctuation">(</span>
    agent<span class="token operator">=</span><span class="token string">'chat-conversational-react-description'</span><span class="token punctuation">,</span>
    tools<span class="token operator">=</span>tools<span class="token punctuation">,</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    max_iterations<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    early_stopping_method<span class="token operator">=</span><span class="token string">'generate'</span><span class="token punctuation">,</span>
    memory<span class="token operator">=</span>conversational_memory
<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><p>The agent type of <code>chat-conversation-react-description</code> tells us a few things about this agent, those are:</p><ul><li><code>chat</code> means the LLM being used is a <em>chat</em> model. Both <code>gpt-4</code> and <code>gpt-3.5-turbo</code> are chat models as they consume conversation history and produce conversational responses. A model like <code>text-davinci-003</code> is <em>not</em> a chat model as it is not designed to be used this way.</li><li><code>conversational</code> means we will be including <code>conversation_memory</code>.</li><li><code>react</code> refers to the <a href="https://arxiv.org/abs/2210.03629"><em>ReAct framework</em></a>, which enables multi-step reasoning and tool usage by giving the model the ability to <em>“converse with itself”</em>.</li><li><code>description</code> tells us that the LLM/agent will decide which tool to use based on their descriptions — which we created in the earlier tool definition.</li></ul><p>With that all in place, we can ask our agent to calculate the circumference of a circle.</p><div class="jupyter-notebook" style="max-height:none"><div class="notebook-cell notebook-input"><div class="exec-count"></div><div class="code-toolbar"><pre class="notebook no-line-numbers language-python line-numbers" tabindex="0"><code class="notebook language-python">agent<span class="token punctuation">(</span><span class="token string">"can you calculate the circumference of a circle that has a radius of 7.81mm"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><div class="notebook-cell notebook-output"><div class="exec-count">Out[]:</div><div class="output"><pre><code>
</code></pre><pre><code>
</code></pre><pre><code>[1m&gt; Entering new AgentExecutor chain...[0m
</code></pre><pre><code>[32;1m[1;3m{
</code></pre><pre><code>    "action": "Final Answer",
</code></pre><pre><code>    "action_input": "The circumference of a circle with a radius of 7.81mm is approximately 49.03mm."
</code></pre><pre><code>}[0m
</code></pre><pre><code>
</code></pre><pre><code>[1m&gt; Finished chain.[0m
</code></pre><pre><code>{'input': 'can you calculate the circumference of a circle that has a radius of 7.81mm',
</code></pre><pre><code> 'chat_history': [],
</code></pre><pre><code> 'output': 'The circumference of a circle with a radius of 7.81mm is approximately 49.03mm.'}</code></pre></div></div><div class="notebook-cell notebook-input"><div class="exec-count"></div><div class="code-toolbar"><pre class="notebook no-line-numbers language-python line-numbers" tabindex="0"><code class="notebook language-python"><span class="token punctuation">(</span><span class="token number">7.81</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> pi<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><div class="notebook-cell notebook-output"><div class="exec-count">Out[]:</div><div class="output"><pre><code>49.071677249072565</code></pre></div></div></div><p>The agent is close, but it isn’t accurate — something is wrong. We can see in the output of the <strong>AgentExecutor Chain</strong> that the agent jumped straight to the <strong>Final Answer</strong> action:</p><div class="highlight"><div class="code-toolbar"><pre class="language-json line-numbers" tabindex="0"><code class="language-json" data-lang="json">{ "action": "Final Answer", "action_input": "The circumference of a circle with a radius of 7.81mm is approximately 49.03mm." }
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><p>The <strong>Final Answer</strong> action is what the agent uses when it has decided it has completed its reasoning and action steps and has all the information it needs to answer the user’s query. That means the agent decided <em>not</em> to use the circumference calculator tool.</p><p>LLMs are generally bad at math, but that doesn’t stop them from trying to do math. The problem is due to the LLM’s overconfidence in its mathematical ability. To fix this, we must tell the model that it <em>cannot</em> do math. First, let’s see the current prompt being used:</p><div class="jupyter-notebook" style="max-height:none"><div class="notebook-cell notebook-input"><div class="exec-count"></div><div class="code-toolbar"><pre class="notebook no-line-numbers language-python line-numbers" tabindex="0"><code class="notebook language-python"><span class="token comment"># existing prompt</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>agent<span class="token punctuation">.</span>agent<span class="token punctuation">.</span>llm_chain<span class="token punctuation">.</span>prompt<span class="token punctuation">.</span>messages<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>prompt<span class="token punctuation">.</span>template<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><div class="notebook-cell notebook-output"><div class="exec-count">Out[]:</div><div class="output"><pre><code>Assistant is a large language model trained by OpenAI.
</code></pre><pre><code>
</code></pre><pre><code>Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.
</code></pre><pre><code>
</code></pre><pre><code>Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.
</code></pre><pre><code>
</code></pre><pre><code>Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.
</code></pre></div></div></div><p>We will add a single sentence that tells the model that it is <em>“terrible at math”</em> and should never attempt to do it.</p><pre><code>Unfortunately, the Assistant is terrible at maths. When provided with math questions, no matter how simple, assistant always refers to its trusty tools and absolutely does NOT try to answer math questions by itself
</code></pre><p>With this added to the original prompt text, we create a new prompt using <code>agent.agent.create_prompt</code> — this will create the correct prompt structure for our agent, including tool descriptions. Then, we update <code>agent.agent.llm_chain.prompt</code>.</p><div class="jupyter-notebook" style="max-height:none"><div class="notebook-cell notebook-input"><div class="exec-count"></div><div class="code-toolbar"><pre class="notebook no-line-numbers language-python line-numbers" tabindex="0"><code class="notebook language-python">sys_msg <span class="token operator">=</span> <span class="token triple-quoted-string string">"""Assistant is a large language model trained by OpenAI.

Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.

Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.

Unfortunately, Assistant is terrible at maths. When provided with math questions, no matter how simple, assistant always refers to it's trusty tools and absolutely does NOT try to answer math questions by itself

Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><div class="notebook-cell notebook-input"><div class="exec-count"></div><div class="code-toolbar"><pre class="notebook no-line-numbers language-python line-numbers" tabindex="0"><code class="notebook language-python">new_prompt <span class="token operator">=</span> agent<span class="token punctuation">.</span>agent<span class="token punctuation">.</span>create_prompt<span class="token punctuation">(</span>
    system_message<span class="token operator">=</span>sys_msg<span class="token punctuation">,</span>
    tools<span class="token operator">=</span>tools
<span class="token punctuation">)</span>

agent<span class="token punctuation">.</span>agent<span class="token punctuation">.</span>llm_chain<span class="token punctuation">.</span>prompt <span class="token operator">=</span> new_prompt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div></div><p>Now we can try again:</p><div class="jupyter-notebook" style="max-height:none"><div class="notebook-cell notebook-input"><div class="exec-count"></div><div class="code-toolbar"><pre class="notebook no-line-numbers language-python line-numbers" tabindex="0"><code class="notebook language-python">agent<span class="token punctuation">(</span><span class="token string">"can you calculate the circumference of a circle that has a radius of 7.81mm"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><div class="notebook-cell notebook-output"><div class="exec-count">Out[]:</div><div class="output"><pre><code>
</code></pre><pre><code>
</code></pre><pre><code>[1m&gt; Entering new AgentExecutor chain...[0m
</code></pre><pre><code>[32;1m[1;3m```json
</code></pre><pre><code>{
</code></pre><pre><code>    "action": "Circumference calculator",
</code></pre><pre><code>    "action_input": "7.81"
</code></pre><pre><code>}
</code></pre><pre><code>```[0m
</code></pre><pre><code>Observation: [36;1m[1;3m49.071677249072565[0m
</code></pre><pre><code>Thought:[32;1m[1;3m```json
</code></pre><pre><code>{
</code></pre><pre><code>    "action": "Final Answer",
</code></pre><pre><code>    "action_input": "The circumference of a circle with a radius of 7.81mm is approximately 49.07mm."
</code></pre><pre><code>}
</code></pre><pre><code>```[0m
</code></pre><pre><code>
</code></pre><pre><code>[1m&gt; Finished chain.[0m
</code></pre><pre><code>{'input': 'can you calculate the circumference of a circle that has a radius of 7.81mm',
</code></pre><pre><code> 'chat_history': [HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),
</code></pre><pre><code>  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.03mm.', additional_kwargs={})],
</code></pre><pre><code> 'output': 'The circumference of a circle with a radius of 7.81mm is approximately 49.07mm.'}</code></pre></div></div></div><p>We can see that the agent now uses the <strong>Circumference calculator</strong> tool and consequently gets the correct answer.</p><h3 id="tools-with-multiple-parameters">Tools With Multiple Parameters</h3><p>In the circumference calculator, we could only input a single value — the <code>radius</code> — more often than not, we will need multiple parameters.</p><p>To demonstrate how to do this, we will build a <em>Hypotenuse calculator</em>. The tool will help us calculate the hypotenuse of a triangle given a combination of triangle side lengths and/or angles.</p><p><img loading="lazy" src="./langchain6_files/langchain-tools-4.png" alt="Hypotenuse calculations" width="100%"></p><p>We want multiple inputs here because we calculate the triangle hypotenuse with different values (the sides and angle). Additionally, we don’t need <em>all</em> values. We can calculate the hypotenuse with any combination of <em>two or more</em> parameters.</p><p>We define our new tool like so:</p><div class="highlight"><div class="code-toolbar"><pre class="language-python line-numbers" tabindex="0"><code class="language-python" data-lang="python"><span class="token keyword">from</span> typing <span class="token keyword">import</span> Optional
<span class="token keyword">from</span> math <span class="token keyword">import</span> sqrt<span class="token punctuation">,</span> cos<span class="token punctuation">,</span> sin

desc <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token string">"use this tool when you need to calculate the length of a hypotenuse"</span>
    <span class="token string">"given one or two sides of a triangle and/or an angle (in degrees). "</span>
    <span class="token string">"To use the tool, you must provide at least two of the following parameters "</span>
    <span class="token string">"['adjacent_side', 'opposite_side', 'angle']."</span>
<span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">PythagorasTool</span><span class="token punctuation">(</span>BaseTool<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">"Hypotenuse calculator"</span>
    description <span class="token operator">=</span> desc
    
    <span class="token keyword">def</span> <span class="token function">_run</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        adjacent_side<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Union<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        opposite_side<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Union<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        angle<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>Union<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># check for the values we have been given</span>
        <span class="token keyword">if</span> adjacent_side <span class="token keyword">and</span> opposite_side<span class="token punctuation">:</span>
            <span class="token keyword">return</span> sqrt<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">(</span>adjacent_side<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token builtin">float</span><span class="token punctuation">(</span>opposite_side<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> adjacent_side <span class="token keyword">and</span> angle<span class="token punctuation">:</span>
            <span class="token keyword">return</span> adjacent_side <span class="token operator">/</span> cos<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">(</span>angle<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> opposite_side <span class="token keyword">and</span> angle<span class="token punctuation">:</span>
            <span class="token keyword">return</span> opposite_side <span class="token operator">/</span> sin<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">(</span>angle<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token string">"Could not calculate the hypotenuse of the triangle. Need two or more of `adjacent_side`, `opposite_side`, or `angle`."</span>
    
    <span class="token keyword">def</span> <span class="token function">_arun</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> NotImplementedError<span class="token punctuation">(</span><span class="token string">"This tool does not support async"</span><span class="token punctuation">)</span>

tools <span class="token operator">=</span> <span class="token punctuation">[</span>PythagorasTool<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><p>In the tool description, we describe the tool functionality in natural language and specify that to <em>“use the tool, you must provide at least two of the following parameters [‘adjacent_side’, ‘opposite_side’, ‘angle’]"</em>. This instruction is all we need for <code>gpt-3.5-turbo</code> to understand the required input format for the function.</p><p>As before, we must update the agent’s prompt. We don’t need to modify the system message as we did before, but we do need to update the available tools described in the prompt.</p><div class="highlight"><div class="code-toolbar"><pre class="language-python line-numbers" tabindex="0"><code class="language-python" data-lang="python">new_prompt <span class="token operator">=</span> agent<span class="token punctuation">.</span>agent<span class="token punctuation">.</span>create_prompt<span class="token punctuation">(</span>
    system_message<span class="token operator">=</span>sys_msg<span class="token punctuation">,</span>
    tools<span class="token operator">=</span>tools
<span class="token punctuation">)</span>

agent<span class="token punctuation">.</span>agent<span class="token punctuation">.</span>llm_chain<span class="token punctuation">.</span>prompt <span class="token operator">=</span> new_prompt
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><p>Unlike before, we must also update the <code>agent.tools</code> attribute with our new tools:</p><div class="highlight"><div class="code-toolbar"><pre class="language-python line-numbers" tabindex="0"><code class="language-python" data-lang="python">agent<span class="token punctuation">.</span>tools <span class="token operator">=</span> tools
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><p>Now we ask a question specifying two of the three required parameters:</p><div class="jupyter-notebook" style="max-height:none"><div class="notebook-cell notebook-input"><div class="exec-count"></div><div class="code-toolbar"><pre class="notebook no-line-numbers language-python line-numbers" tabindex="0"><code class="notebook language-python">agent<span class="token punctuation">(</span><span class="token string">"If I have a triangle with two sides of length 51cm and 34cm, what is the length of the hypotenuse?"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><div class="notebook-cell notebook-output"><div class="exec-count">Out[]:</div><div class="output"><pre><code>
</code></pre><pre><code>
</code></pre><pre><code>[1m&gt; Entering new AgentExecutor chain...[0m
</code></pre><pre><code class="error">WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.&lt;locals&gt;._completion_with_retry in 1.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.
</code></pre><pre><code>[32;1m[1;3m{
</code></pre><pre><code>    "action": "Hypotenuse calculator",
</code></pre><pre><code>    "action_input": {
</code></pre><pre><code>        "adjacent_side": 34,
</code></pre><pre><code>        "opposite_side": 51
</code></pre><pre><code>    }
</code></pre><pre><code>}[0m
</code></pre><pre><code>Observation: [36;1m[1;3m61.29437168288782[0m
</code></pre><pre><code>Thought:[32;1m[1;3m{
</code></pre><pre><code>    "action": "Final Answer",
</code></pre><pre><code>    "action_input": "The length of the hypotenuse is approximately 61.29cm."
</code></pre><pre><code>}[0m
</code></pre><pre><code>
</code></pre><pre><code>[1m&gt; Finished chain.[0m
</code></pre><pre><code>{'input': 'If I have a triangle with two sides of length 51cm and 34cm, what is the length of the hypotenuse?',
</code></pre><pre><code> 'chat_history': [HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),
</code></pre><pre><code>  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.03mm.', additional_kwargs={}),
</code></pre><pre><code>  HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),
</code></pre><pre><code>  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.07mm.', additional_kwargs={})],
</code></pre><pre><code> 'output': 'The length of the hypotenuse is approximately 61.29cm.'}</code></pre></div></div></div><p>The agent correctly identifies the correct parameters and passes them to our tool. We can try again with different parameters:</p><div class="jupyter-notebook" style="max-height:none"><div class="notebook-cell notebook-input"><div class="exec-count"></div><div class="code-toolbar"><pre class="notebook no-line-numbers language-python line-numbers" tabindex="0"><code class="notebook language-python">agent<span class="token punctuation">(</span><span class="token string">"If I have a triangle with the opposite side of length 51cm and an angle of 20 deg, what is the length of the hypotenuse?"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><div class="toolbar"><div class="toolbar-item"><button class="copy-to-clipboard-button" type="button" data-copy-state="copy"><span>Copy</span></button></div></div></div></div><div class="notebook-cell notebook-output"><div class="exec-count">Out[]:</div><div class="output"><pre><code>
</code></pre><pre><code>
</code></pre><pre><code>[1m&gt; Entering new AgentExecutor chain...[0m
</code></pre><pre><code>[32;1m[1;3m{
</code></pre><pre><code>    "action": "Hypotenuse calculator",
</code></pre><pre><code>    "action_input": {
</code></pre><pre><code>        "opposite_side": 51,
</code></pre><pre><code>        "angle": 20
</code></pre><pre><code>    }
</code></pre><pre><code>}[0m
</code></pre><pre><code>Observation: [36;1m[1;3m55.86315275680817[0m
</code></pre><pre><code>Thought:[32;1m[1;3m{
</code></pre><pre><code>    "action": "Final Answer",
</code></pre><pre><code>    "action_input": "The length of the hypotenuse is approximately 55.86cm."
</code></pre><pre><code>}[0m
</code></pre><pre><code>
</code></pre><pre><code>[1m&gt; Finished chain.[0m
</code></pre><pre><code>{'input': 'If I have a triangle with the opposite side of length 51cm and an angle of 20 deg, what is the length of the hypotenuse?',
</code></pre><pre><code> 'chat_history': [HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),
</code></pre><pre><code>  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.03mm.', additional_kwargs={}),
</code></pre><pre><code>  HumanMessage(content='can you calculate the circumference of a circle that has a radius of 7.81mm', additional_kwargs={}),
</code></pre><pre><code>  AIMessage(content='The circumference of a circle with a radius of 7.81mm is approximately 49.07mm.', additional_kwargs={}),
</code></pre><pre><code>  HumanMessage(content='If I have a triangle with two sides of length 51cm and 34cm, what is the length of the hypotenuse?', additional_kwargs={}),
</code></pre><pre><code>  AIMessage(content='The length of the hypotenuse is approximately 61.29cm.', additional_kwargs={})],
</code></pre><pre><code> 'output': 'The length of the hypotenuse is approximately 55.86cm.'}</code></pre></div></div></div><p>Again, we see correct tool usage. Even with our short tool description, the agent can consistently use the tool as intended and with multiple parameters.</p><h3 id="more-advanced-tool-usage">More Advanced Tool Usage</h3><p>We’ve seen two examples of custom tools. In most scenarios, we’d likely want to do something more powerful — so let’s give that a go.</p><p>Taking inspiration from the HuggingGPT paper <sup>[1]</sup>, we will take an existing open-source <em>expert model</em> that has been trained for a specific task that our LLM cannot do.</p><p>That model will be the <a href="https://huggingface.co/Salesforce/blip-image-captioning-large"><code>Salesforce/blip-image-captioning-large</code></a> model hosted on Hugging Face. This model takes an image and describes it, something that we cannot do with our LLM.</p><p>To begin, we need to initialize the model like so:</p><div class="highlight"><div class="code-toolbar"><pre class="language-python line-numbers" tabindex="0"><code class="language-python" data-lang="python"><span class="token comment"># !pip install transformers</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> BlipProcessor<span class="token punctuation">,</span> BlipForConditionalGeneration


<span class="token comment"># specify model to be used</span>
hf_model <span class="token operator">=</span> <span class="token string">"Salesforce/blip-image-captioning-large"</span>
<span class="token comment"># use GPU if it's available</span>
device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>

<span class="token comment"># preprocessor will prepare images for the model</span>
processor <span class="token operator">=</span> BlipProcessor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>hf_model<span class="token punctuation">)</span>
<span class="token comment"># then we initialize the model itself</span>
model <span class="token operator">=</span> BlipForConditionalGeneration<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>hf_model<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="toolbar"><div 